{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import subprocess\n",
    "import logging\n",
    "from concurrent import futures\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from ipywidgets import Play, IntSlider, jslink, HBox, interactive_output\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTSET_DIR = os.path.join('/home', 'jovyan', 'work', '01_testset')\n",
    "PRJ_DIR = os.path.join('/home', 'jovyan', 'work', '03_opt')\n",
    "PROG_PATH = os.path.join(PRJ_DIR, 'main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マスタの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_seed_df = pd.read_csv(os.path.join(TESTSET_DIR, '01_testset_pre_master.csv'), usecols=['seed'])\n",
    "sys_seed_df = pd.read_csv(os.path.join(TESTSET_DIR, '02_testset_sys_master.csv'), usecols=['seed'])\n",
    "stress_seed_df = pd.read_csv(os.path.join(TESTSET_DIR, '03_testset_stress_master.csv'), usecols=['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAMP_TAG = 'yyyymmdd_hhmm'\n",
    "CHAMP_DIR = os.path.join('/home', 'jovyan', 'work', 'result', 'champion')\n",
    "\n",
    "champ_path = os.path.join(CHAMP_DIR, 'champ_all_{}.csv'.format(CHAMP_TAG))\n",
    "champ_df = pd.read_csv(champ_path)\n",
    "\n",
    "champ_score_dict = {}\n",
    "\n",
    "for _, row in champ_df.iterrows():\n",
    "    seed = row['seed']\n",
    "    score = row['champion_score']\n",
    "\n",
    "    champ_score_dict[seed] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行するロジックの指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行プログラムにタグをつけておく\n",
    "PROG_TAG = 'prog-tag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(seed, param_list):\n",
    "    problem_path = os.path.join(TESTSET_DIR, 'in', '{:0>4}.txt'.format(seed)) \n",
    "    param_str = ' '.join(map(str, param_list))\n",
    "    command_str = 'echo {} {} | {}'.format(problem_path, param_str, PROG_PATH)\n",
    "\n",
    "    # stack overflow対策\n",
    "    # command_str = 'ulimit -S -s 1048576 && echo {} | {}'.format(problem_path, PROG_PATH)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    res = subprocess.run(command_str, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "\n",
    "    # 経過時間(ミリ秒単位)\n",
    "    e_time = time.perf_counter() - start_time\n",
    "    e_time = int(1000 * e_time)    \n",
    "    \n",
    "    #print('{}'.format(prob_id))    \n",
    "    return (seed, e_time, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(testset_name):\n",
    "    result_df = pd.DataFrame()\n",
    "    future_list = []\n",
    "\n",
    "    logger.info('Start')\n",
    "\n",
    "    testset_path = os.path.join(TESTSET_DIR, testset_name + '_master.csv')\n",
    "    testset_df = pd.read_csv(testset_path)\n",
    "\n",
    "    # 24並列実行\n",
    "    with futures.ThreadPoolExecutor(max_workers=24) as executor:\n",
    "        seed_list = testset_df['seed'].to_list()\n",
    "        future_list = list(tqdm(executor.map(solve, seed_list), total=len(seed_list)))\n",
    "\n",
    "    for future in future_list:\n",
    "        seed, e_time, res = future\n",
    "\n",
    "        # 結果をまとめる\n",
    "        solve_result = []\n",
    "        \n",
    "        solve_result.append(testset_name)\n",
    "\n",
    "        # 問題パラメタ\n",
    "        solve_result.append(seed)\n",
    "\n",
    "        # 経過時間\n",
    "        solve_result.append(e_time)\n",
    "        \n",
    "        try:\n",
    "            # -- start -- 生成コード貼り付け先\n",
    "            elem_cnt = 2\n",
    "\n",
    "            result = str(res.stderr.decode('utf-8').split()[-elem_cnt + 0].replace('Result=', ''))\n",
    "            score = int(res.stderr.decode('utf-8').split()[-elem_cnt + 1].replace('Score=', ''))\n",
    "\n",
    "            solve_result.append(score)\n",
    "            solve_result.append(result)   \n",
    "            # -- end -- 生成コード貼り付け先\n",
    "\n",
    "            # 相対スコア\n",
    "            # rel_score = int(10 ** 9 * top_rate * champ_score_dict[seed] / score)\n",
    "            # solve_result.append(rel_score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Error: seed={}'.format(seed))\n",
    "            print(e)\n",
    "            return\n",
    "\n",
    "        result_df = pd.concat([result_df, pd.DataFrame(solve_result).T], axis=0)\n",
    "\n",
    "    logger.info('finish!')\n",
    "    \n",
    "    # 結果を整形\n",
    "    result_df.index = range(result_df.shape[0])\n",
    "    cols = ['testset', 'seed', 'time', 'score', 'result']\n",
    "    result_df.columns = cols\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "fmt = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_df(result_df):\n",
    "    # 全体サマリ\n",
    "    summary_all_df = pd.DataFrame()\n",
    "\n",
    "    for testset in np.unique(result_df['testset']):\n",
    "        test_result_df = result_df.query('testset == \"{}\"'.format(testset))\n",
    "\n",
    "        summary_df = pd.DataFrame(\n",
    "        {\n",
    "            'testset': [testset],\n",
    "            \n",
    "            'time_mean': [int(np.mean(test_result_df['time']))],\n",
    "            \n",
    "            # -- start -- 生成コード貼り付け先\n",
    "            'score_mean': [np.mean(test_result_df['score'])],\n",
    "            'score_min': [min(test_result_df['score'])],\n",
    "            'score_max': [max(test_result_df['score'])],\n",
    "            # -- end -- 生成コード貼り付け先\n",
    "\n",
    "            'time_max': [max(test_result_df['time'])],\n",
    "        })\n",
    "\n",
    "        summary_all_df = pd.concat([summary_all_df, summary_df], axis=0)   \n",
    "\n",
    "    summary_all_df['tag'] = PROG_TAG\n",
    "    \n",
    "    cols = ['tag']\n",
    "    cols.extend(summary_df.columns)\n",
    "    \n",
    "    summary_all_df = summary_all_df[cols]\n",
    "    \n",
    "    return summary_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 15:46:03,187: Start\n",
      "2023-03-30 15:46:15,029: finish!\n"
     ]
    }
   ],
   "source": [
    "#testset_name = '01_testset_pre'\n",
    "#testset_name = '02_testset_sys'\n",
    "#testset_name = '03_testset_stress'\n",
    "testset_name = '04_testset_param'\n",
    "\n",
    "result_dict = {}\n",
    "summary_all_dict = {}\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "init_param_list = []\n",
    "\n",
    "testset_result_df = run_test(testset_name, init_param_list)\n",
    "result_df = pd.concat([result_df, testset_result_df], axis=0)\n",
    "\n",
    "result_dict[PROG_NAME] = result_df\n",
    "summary_all_dict[PROG_NAME] = get_summary_df(result_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testset_result_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(param_list):\n",
    "    testset_name = '04_testset_param'\n",
    "    testset_result_df = run_test(testset_name, param_list)\n",
    "    \n",
    "    score = np.mean(testset_result_df['log_score'])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    target_double_up_turn = trial.suggest_int('target_double_up_turn', 840, 900) \n",
    "    \n",
    "    double_up_cost_ub0 = trial.suggest_int('double_up_cost_ub0', 880, 950) \n",
    "    double_up_cost_ub1 = trial.suggest_int('double_up_cost_ub1', 430, 500) \n",
    "    double_up_cost_ub2 = trial.suggest_int('double_up_cost_ub2', 350, 450) \n",
    "    double_up_cost_ub3 = trial.suggest_int('double_up_cost_ub3', 270, 340) \n",
    "    double_up_cost_ub4 = trial.suggest_int('double_up_cost_ub4', 580, 700) \n",
    "\n",
    "    stack_money_lb = trial.suggest_int('stack_money_lb', 370, 460) \n",
    "    stack_turn = trial.suggest_int('stack_turn', 620, 720) \n",
    "\n",
    "    param_list = []\n",
    "\n",
    "    param_list.append(target_double_up_turn)\n",
    "\n",
    "    param_list.append(double_up_cost_ub0)\n",
    "    param_list.append(double_up_cost_ub1)\n",
    "    param_list.append(double_up_cost_ub2)\n",
    "    param_list.append(double_up_cost_ub3)\n",
    "    param_list.append(double_up_cost_ub4)\n",
    "    \n",
    "    param_list.append(stack_money_lb)\n",
    "    param_list.append(stack_turn)\n",
    "    \n",
    "    return calc_score(param_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-30 16:05:06,867]\u001b[0m A new study created in memory with name: no-name-104bcd88-f1a7-4cd6-a818-2336e91665e1\u001b[0m\n",
      "2023-03-30 16:05:06,868: Start\n",
      "2023-03-30 16:05:28,749: finish!\n",
      "\u001b[32m[I 2023-03-30 16:05:28,750]\u001b[0m Trial 0 finished with value: 1834.0 and parameters: {'invalid_shift': 68, 'invalid_clear': 1}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:05:28,751: Start\n",
      "2023-03-30 16:05:49,202: finish!\n",
      "\u001b[32m[I 2023-03-30 16:05:49,204]\u001b[0m Trial 1 finished with value: 2043.0 and parameters: {'invalid_shift': 97, 'invalid_clear': 13}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:05:49,205: Start\n",
      "2023-03-30 16:06:10,889: finish!\n",
      "\u001b[32m[I 2023-03-30 16:06:10,890]\u001b[0m Trial 2 finished with value: 1969.0 and parameters: {'invalid_shift': 65, 'invalid_clear': 12}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:06:10,891: Start\n",
      "2023-03-30 16:06:30,843: finish!\n",
      "\u001b[32m[I 2023-03-30 16:06:30,844]\u001b[0m Trial 3 finished with value: 2047.0 and parameters: {'invalid_shift': 94, 'invalid_clear': 3}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:06:30,845: Start\n",
      "2023-03-30 16:06:52,495: finish!\n",
      "\u001b[32m[I 2023-03-30 16:06:52,496]\u001b[0m Trial 4 finished with value: 2022.0 and parameters: {'invalid_shift': 63, 'invalid_clear': 19}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:06:52,497: Start\n",
      "2023-03-30 16:07:14,628: finish!\n",
      "\u001b[32m[I 2023-03-30 16:07:14,629]\u001b[0m Trial 5 finished with value: 1902.0 and parameters: {'invalid_shift': 67, 'invalid_clear': 6}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:07:14,630: Start\n",
      "2023-03-30 16:07:35,091: finish!\n",
      "\u001b[32m[I 2023-03-30 16:07:35,092]\u001b[0m Trial 6 finished with value: 1906.0 and parameters: {'invalid_shift': 85, 'invalid_clear': 3}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:07:35,093: Start\n",
      "2023-03-30 16:07:56,208: finish!\n",
      "\u001b[32m[I 2023-03-30 16:07:56,209]\u001b[0m Trial 7 finished with value: 1858.0 and parameters: {'invalid_shift': 77, 'invalid_clear': 3}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:07:56,210: Start\n",
      "2023-03-30 16:08:18,952: finish!\n",
      "\u001b[32m[I 2023-03-30 16:08:18,953]\u001b[0m Trial 8 finished with value: 1976.0 and parameters: {'invalid_shift': 62, 'invalid_clear': 13}. Best is trial 0 with value: 1834.0.\u001b[0m\n",
      "2023-03-30 16:08:18,954: Start\n",
      "2023-03-30 16:08:41,754: finish!\n",
      "\u001b[32m[I 2023-03-30 16:08:41,755]\u001b[0m Trial 9 finished with value: 1848.0 and parameters: {'invalid_shift': 54, 'invalid_clear': 3}. Best is trial 0 with value: 1834.0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "study.enqueue_trial({'target_double_up_turn': init_param_list[0],\n",
    "                    'double_up_cost_ub0': init_param_list[1],\n",
    "                    'double_up_cost_ub1': init_param_list[2],\n",
    "                    'double_up_cost_ub2': init_param_list[3],\n",
    "                    'double_up_cost_ub3': init_param_list[4],\n",
    "                    'double_up_cost_ub4': init_param_list[5],\n",
    "                     \n",
    "                    'stack_money_lb': init_param_list[6],\n",
    "                    'stack_turn': init_param_list[7],\n",
    "                    })\n",
    "\n",
    "study.optimize(objective, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'invalid_shift': 68, 'invalid_clear': 1}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
